{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdeac1a",
   "metadata": {},
   "source": [
    "## Hybrid Retrieval and Agent Integration - PoC\n",
    "Here, we will integrate the hybrid search retrieval mechanism with the Data-Analyst agent.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d67d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import traceback\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from pyjstat import pyjstat\n",
    "from textwrap import dedent\n",
    "from pyjstat import pyjstat\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Dict, List, Any, Literal, Annotated\n",
    "\n",
    "from langgraph.types import Command\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, AIMessage, ToolMessage\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langchain_core.tools import tool, InjectedToolCallId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57faa926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "root = Path().absolute().parents[1]\n",
    "os.chdir(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a49dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_low = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature=1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "llm_med = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "llm_high  = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2e5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_python_safely(code: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Minimal sandbox runner. In production: isolate with subprocess, container, time & mem limits.\n",
    "    Returns {\"stdout\": str, \"error\": {\"type\":, \"message\":, \"trace\":}} on failure.\n",
    "    \"\"\"\n",
    "    stdout_capture = io.StringIO()\n",
    "    old_stdout, old_stderr = sys.stdout, sys.stderr\n",
    "    sys.stdout = stdout_capture\n",
    "    sys.stderr = stdout_capture  # co-mingle\n",
    "    globals_dict = {\"__name__\": \"__main__\"}\n",
    "    try:\n",
    "        exec(code, globals_dict, globals_dict)\n",
    "        out = stdout_capture.getvalue()\n",
    "        return {\"stdout\": out}\n",
    "    except Exception as e:\n",
    "        err = {\"type\": e.__class__.__name__, \"message\": str(e), \"trace\": traceback.format_exc()}\n",
    "        return {\"stdout\": stdout_capture.getvalue(), \"error\": err}\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_stdout, old_stderr\n",
    "\n",
    "@tool(name_or_callable=\"python_code_executor\", parse_docstring=True)\n",
    "def python_code_executor(\n",
    "    code: str,\n",
    "    description: str,\n",
    "    state: Annotated[dict, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Executes the given Python code and returns the output.\n",
    "    \n",
    "    Args:\n",
    "        code (str): The Python code to execute.\n",
    "        description (str): A short description of the code being executed.\n",
    "    \n",
    "    Returns:\n",
    "        str: The output of the executed code.\n",
    "    \"\"\"\n",
    "    print(\"Executing code in python_code_executor: \", description)\n",
    "    result = _run_python_safely(code)\n",
    "    print(\"Result from python_code_executor: \", result['stdout'])\n",
    "\n",
    "    if 'error' in result:\n",
    "        return Command(\n",
    "            update={\n",
    "                \"scratchpad\": [\n",
    "                    ToolMessage(\n",
    "                        content=f\"Error executing code: {result['error']}\",\n",
    "                        tool_call_id=tool_call_id,\n",
    "                        name=\"python_code_executor\"\n",
    "                    )\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"scratchpad\": [\n",
    "                ToolMessage(\n",
    "                    content=result['stdout'],\n",
    "                    # content=\"Context updated with required analysis.\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                    name=\"python_code_executor\"\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "TOOLS = [python_code_executor]\n",
    "\n",
    "llm_med_with_code_exec_tool = llm_med.bind_tools(TOOLS, allowed_function_names=[\"python_code_executor\"])\n",
    "llm_high_with_code_exec_tool = llm_high.bind_tools(TOOLS, allowed_function_names=[\"python_code_executor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffe2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"State for the analyst agent.\"\"\"\n",
    "    scratchpad: Annotated[list[BaseMessage], add_messages] = Field(default=[], description=\"The scratchpad for the agent.\")\n",
    "    context: str = Field(default=None, description=\"The context for the agent to use.\")\n",
    "    iters: int = Field(default=0, description=\"The number of iterations the agent has gone through.\")\n",
    "    sub_question: str = Field(description=\"The question asked by the user.\")\n",
    "    table_id: str = Field(description=\"The ID of the table being queried.\")\n",
    "    # csv_fp: str = Field(default=\"\", description=\"The file path to the CSV file containing the CSO data.\")\n",
    "    # code: str = Field(default=\"\", description=\"The python code to run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39661d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.json_stat_archive_db import JSONStatArchiveDB\n",
    "\n",
    "cso_archive_reader = JSONStatArchiveDB(compression_level=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f15c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_ANALYST = dedent(\n",
    "    f\"\"\"\\\n",
    "        # ROLE: I am a Data Analyst Agent that has access to Python-shell tool/function - `python_code_executor(code: str, description: str)`.\n",
    "\n",
    "        # INSTRUCTIONS:\n",
    "            - I call the `python_code_executor` tool to analyse the data.\n",
    "            - Once I feel I know enough, I give a crisp and concise answer to the user's question.\n",
    "\n",
    "        # NOTE:\n",
    "            - The python-script should import necessary libraries (pandas, numpy, os, pathlib, etc) to read the CSV file and perform data manipulation \n",
    "            - The python-script use `print` statements for printing any statistics that you need to fetch.\n",
    "            - In a single tool-call to `python_code_executor`, I ask for a single statistic to be fetched.\n",
    "            - I keep the commentary limited in this step.\n",
    "            - Once I have enough statistics to answer the user's question, I give a crisp and concise answer to user's question, with proper data backing it up.\n",
    "        \n",
    "        # WARNINGS:\n",
    "            - For tool-calls to `python_code_executor` tool, only send the python code as `code` parameter\n",
    "            - Do not include any visualizations or plots in the code.\n",
    "            - In case I get reported back with any errors in executing the python code, I should make necessary corrections and call the python_code_executor tool to re-run the code.\n",
    "        \n",
    "        # TIPS:\n",
    "            - For high cardinality columns, consider using simple keyword based filtering (like `str.contains('abc|xyz')`). Also consider items / categories related to said keywords.\n",
    "    \"\"\"\n",
    ")\n",
    "def _create_table_analysis(df: pd.DataFrame, table_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyzes the table and returns a dictionary with the analysis results.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the CSO data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the analysis results.\n",
    "    \"\"\"\n",
    "    csv_fp = f\"cache/{table_id}.csv\"\n",
    "    try:\n",
    "        table_shape = df.shape\n",
    "        table_sample = pd.concat([df.head(5), df.tail(5)]) if len(df) > 10 else df\n",
    "        \n",
    "        table_info_df = pd.DataFrame({\n",
    "            \"columns\": df.columns,\n",
    "            \"dtypes\": [str(df[col].dtype) for col in df.columns],\n",
    "            \"nunique\": [df[col].nunique() if df[col].nunique() <= 50 else '>50' for col in df.columns],\n",
    "            \"nulls\": [df[col].isnull().sum() for col in df.columns]\n",
    "        })\n",
    "\n",
    "        context_list = [\n",
    "            \"CONTEXT:\",\n",
    "            f\"- **CSV File Path**: {csv_fp}\",\n",
    "            f\"- **Table Shape**: {table_shape}\",\n",
    "            \"- **Table Info**:\",\n",
    "            table_info_df.to_string(index=False),\n",
    "            \"- **Table Sample (first and last 5 rows)**:\",\n",
    "            table_sample.to_string(index=False),\n",
    "        ]\n",
    "\n",
    "    except Exception as e:\n",
    "        context_list = None\n",
    "\n",
    "    return context_list\n",
    "\n",
    "def analyst_agent(state: State) -> str:\n",
    "    \"\"\"\n",
    "    The analyst agent has access to the Python-Shell tool and uses it answer the user query by analysing the data available in context.\n",
    "\n",
    "    Args:\n",
    "        state (State): The state containing the messages and other data.\n",
    "    \n",
    "    Returns:\n",
    "        str: The response from the analyst agent.\n",
    "    \"\"\"\n",
    "    sub_question = state[\"sub_question\"]\n",
    "    old_messages = state[\"scratchpad\"]\n",
    "    system_prompt = SYSTEM_PROMPT_ANALYST\n",
    "    iters = state.get(\"iters\", 0)\n",
    "    table_id = state[\"table_id\"]\n",
    "    iters += 1\n",
    "\n",
    "    csv_save_dir = \"cache/\"\n",
    "    csv_fp = csv_save_dir + f\"{table_id}.csv\"\n",
    "\n",
    "    # check if \"<table_id>.csv\" exists. If not, read the pyjstat-file from artifacts and save the DataFrame as \"<table_id>.csv\"\n",
    "    if not os.path.exists(csv_fp):\n",
    "        for _, ds, _ in cso_archive_reader.read(\"artifacts/cso_bkp/cso_archive/jsonstat_archive.sqlite\", table_id=table_id, with_labels=True):\n",
    "            df: pd.DataFrame = pyjstat.from_json_stat(ds)[0]\n",
    "        df.to_csv(csv_fp, index=False)\n",
    "\n",
    "    if state.get(\"context\", None) is None:\n",
    "        df = pd.read_csv(csv_fp)\n",
    "        context_list = _create_table_analysis(df, table_id)\n",
    "        context = \"\\n\".join(context_list) if context_list else \"No context available.\"\n",
    "    else:\n",
    "        context = state[\"context\"]\n",
    "\n",
    "    msgs = [\n",
    "        SystemMessage(content=system_prompt, name=\"analyst_agent\"),\n",
    "        SystemMessage(content=context, name=\"analyst_agent\"),\n",
    "        HumanMessage(content=sub_question, name=\"analyst_agent\"),\n",
    "    ] + old_messages\n",
    "    \n",
    "    if iters <= 10:\n",
    "        print(\"Running data-analyst agent...\")\n",
    "        res = llm_med_with_code_exec_tool.invoke(msgs)\n",
    "    else:\n",
    "        print(\"Stopping tool-calls as max-iterations reached. Generating final response...\")\n",
    "        res = llm_med.invoke(msgs)\n",
    "        return {\"scratchpad\": [res], \"iters\": iters, \"context\": context}\n",
    "    \n",
    "    if isinstance(res, AIMessage):\n",
    "        return {\"scratchpad\": [res], \"iters\": iters, \"context\": context}\n",
    "    else:\n",
    "        res = AIMessage(\"Error generating code.\")\n",
    "        return {\"scratchpad\": [res], \"iters\": iters, \"context\": context}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad85c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_tool_calls(msg: AIMessage) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the AIMessage has tool calls.\n",
    "    \n",
    "    Args:\n",
    "        msg (AIMessage): The AI message to check.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the message has tool calls, False otherwise.\n",
    "    \"\"\"\n",
    "    return getattr(msg, \"tool_calls\", None) is not None or \\\n",
    "           bool(getattr(msg, \"additional_kwargs\", {}).get(\"function_call\") or \\\n",
    "                getattr(msg, \"additional_kwargs\", {}).get(\"tool_calls\"))\n",
    "\n",
    "\n",
    "def custom_tools_condition(state: State) -> bool:\n",
    "    \"\"\"\n",
    "    Route the LLM based on tool calls in the last message.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the graph.\n",
    "    \n",
    "    Returns:\n",
    "        str: \"tools\" if the last message has tool calls, \"end\" otherwise.\n",
    "    \"\"\"\n",
    "    messages_key = \"scratchpad\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif isinstance(state, dict) and (messages := state.get(messages_key, [])):\n",
    "        ai_message = messages[-1]\n",
    "    elif messages := getattr(state, messages_key, []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99221cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(TOOLS, messages_key=\"scratchpad\")\n",
    "\n",
    "analyst_graph_builder = StateGraph(State)\n",
    "\n",
    "analyst_graph_builder.add_node(\"analyst_agent\", analyst_agent)\n",
    "analyst_graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "analyst_graph_builder.add_edge(START, \"analyst_agent\")\n",
    "analyst_graph_builder.add_conditional_edges(\"analyst_agent\", custom_tools_condition, {\"__end__\": END, \"tools\": \"tools\"})\n",
    "# analyst_graph_builder.add_conditional_edges(\"analyst_agent\", custom_tools_condition, {\"end\": END, \"tools\": \"tools\"})\n",
    "analyst_graph_builder.add_edge(\"tools\", \"analyst_agent\")\n",
    "\n",
    "analyst_graph = analyst_graph_builder.compile()\n",
    "# analyst_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c6874",
   "metadata": {},
   "source": [
    "### Create parent graph for Analyst Agent\n",
    "The parent graph will contain the `reviewer` agent. It will perform the following tasks -\n",
    "- Retrieve upto top 20 relevant resources using the `HybridRetrieval` engine\n",
    "- Select upto top 5 most relevant resources (table-IDs)\n",
    "- Manually enforce tool-calls to the analyst-agent subgraph *(Note that we'll be using the analyst-agent as a tool)*\n",
    "- The `reviewer` agent will have input and output transformation nodes, because the parent graph and the subgraph have separate state schemas (read the official [LangGraph documentation](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#using-different-state-schemas) for more details)\n",
    "\n",
    "Let's build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45eb49fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ParentState(TypedDict):\n",
    "    \"\"\"State for the parent graph.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages] = Field(default=[], description=\"The messages for the parent graph.\")\n",
    "    question: str = Field(description=\"The question asked by the user.\")\n",
    "    iter: int = Field(default=0, description=\"The iteration count for the current state.\")\n",
    "\n",
    "\n",
    "class TableSelectionSubclass(BaseModel):\n",
    "    table_id: str = Field(description=\"Table ID.\")\n",
    "    explanation: str = Field(description=\"Concise 1-liner explanation behind why this table is relevant.\")\n",
    "\n",
    "\n",
    "class TableSelection(BaseModel):\n",
    "    relevant_tables: list[TableSelectionSubclass] = Field(description=\"List of relevant tables with explanations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd42c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.helpers.hybrid_retrieval import HybridRetrieval\n",
    "\n",
    "\n",
    "retriever = HybridRetrieval(top_k_stage_1=200, top_k_stage_2=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "def _create_context(table_ids: list) -> str:\n",
    "    context = []\n",
    "    for table_id in table_ids:\n",
    "        doc = retriever.vector_store.docstore.search(table_id)\n",
    "        sample_questions_str = \"\\n  - \".join(doc.metadata[\"sample_questions\"])\n",
    "        text_chunk_list = [\n",
    "            f\"**Table ID**: {doc.id}\",\n",
    "            f\"**Table Name (and Category)**: {doc.metadata['table_name']} ({doc.metadata['subject']}: {doc.metadata['product']})\",\n",
    "            f\"**Table Summary**: {doc.metadata['description']}\",\n",
    "            f\"**Fields**: {', '.join(doc.metadata['columns'])}\",\n",
    "            f\"**Sample Questions**:\",\n",
    "            f\"  - {sample_questions_str}\"\n",
    "        ]\n",
    "        text_chunk = \"\\n\".join(text_chunk_list)\n",
    "        context.append(text_chunk)\n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "def reviewer_agent(state: ParentState):\n",
    "    messages = state[\"messages\"]\n",
    "    question = state[\"question\"]\n",
    "    iter = state.get(\"iter\", 0) + 1\n",
    "    \n",
    "    if messages and isinstance(messages[-1], ToolMessage):\n",
    "        msgs = [\n",
    "            SystemMessage(content=\"I'm a helpful assistant. My job is to answer the user-question given the context in detail, using all the facts available. Also, specify the sources (table-IDs would be best)\"),\n",
    "            HumanMessage(content=question),\n",
    "        ] + messages\n",
    "        summary_res = llm_med.invoke(msgs)\n",
    "        return {\n",
    "            \"messages\": [summary_res],\n",
    "            \"iter\": iter\n",
    "        }\n",
    "\n",
    "    print(\"REVIEWER_AGENT: Running Hybrid Retrieval...\")\n",
    "    # response = retriever.search(query=question)\n",
    "    # top_20_table_ids = response.sort_values(by=\"stage_2_score\", ascending=True)[:20][\"id\"].tolist()\n",
    "    # print(f\"REVIEWER_AGENT: Hybrid Retrieval fetched {len(top_20_table_ids)} table IDs\")\n",
    "    # context = _create_context(top_20_table_ids)\n",
    "    # prompt_list = [\n",
    "    #     \"Given the following tables context, select up to 3 of the possible relevant tables based on the question asked.\",\n",
    "    #     \"\",\n",
    "    #     \"Table context:\",\n",
    "    #     context,\n",
    "    #     \"\",\n",
    "    #     \"question: \" + question,\n",
    "    # ]\n",
    "    # prompt = \"\\n\".join(prompt_list)\n",
    "    # response = llm_med.with_structured_output(TableSelection).invoke(prompt)\n",
    "    # response_dict = response.model_dump()\n",
    "\n",
    "    # relevant_tables_ids = [\n",
    "    #     item[\"table_id\"] for item in response_dict[\"relevant_tables\"]\n",
    "    # ]\n",
    "    relevant_tables_ids = retriever.search(query=question)\n",
    "    print(f\"REVIEWER_AGENT: LLM selected {len(relevant_tables_ids)} relevant tables.\")\n",
    "\n",
    "    if iter > 2:\n",
    "        print(\"REVIEWER_AGENT: Iteration limit reached.\")\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Max iteration limit reached.\")],\n",
    "            \"iter\": iter\n",
    "        }\n",
    "    \n",
    "    if not relevant_tables_ids:\n",
    "        print(\"REVIEWER_AGENT: No relevant tables found.\")\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"No relevant tables found.\")],\n",
    "            \"iter\": iter\n",
    "        }\n",
    "    else:\n",
    "        print(f\"REVIEWER_AGENT: Making tool calls...\")\n",
    "        tool_calls = [\n",
    "            {\n",
    "                \"name\": \"data_analyst_tool\",\n",
    "                \"args\": {\n",
    "                    \"table_id\": id,\n",
    "                    \"question\": question\n",
    "                },\n",
    "                \"id\": str(uuid4())\n",
    "            } for id in relevant_tables_ids\n",
    "        ]\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"I've found some relevant resources. Let me do a quick analysis.\", tool_calls=tool_calls)],\n",
    "            \"iter\": iter\n",
    "        }\n",
    "\n",
    "def summariser_agent(state: ParentState):\n",
    "    msgs = state[\"messages\"]\n",
    "    res = llm_med.invoke(msgs)\n",
    "    return {\n",
    "        \"messages\": [res],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8ea98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_parent_tools_condition(state: State) -> bool:\n",
    "    \"\"\"\n",
    "    Route the LLM based on tool calls in the last message.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the graph.\n",
    "    \n",
    "    Returns:\n",
    "        str: \"tools\" if the last message has tool calls, \"summariser_agent\" otherwise.\n",
    "    \"\"\"\n",
    "    messages_key = \"messages\"\n",
    "\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif isinstance(state, dict) and (messages := state.get(messages_key, [])):\n",
    "        ai_message = messages[-1]\n",
    "    elif messages := getattr(state, messages_key, []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"summariser_agent\"\n",
    "\n",
    "@tool(\"data_analyst_tool\", parse_docstring=True)\n",
    "def data_analyst_tool(\n",
    "    table_id: str,\n",
    "    question: str,\n",
    "    # state: Annotated[dict, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "):\n",
    "    \"\"\"\n",
    "    Tool to invoke the data analyst agent with a specific table ID and question.\n",
    "    \n",
    "    Args:\n",
    "        table_id (str): The ID of the table to analyze.\n",
    "        question (str): The question to ask the data analyst.\n",
    "\n",
    "    Returns:\n",
    "        Command: The command to update the chat with the data analyst's response.\n",
    "    \"\"\"\n",
    "    print(\"DATA_ANALYST_TOOL: Invoking data analyst tool...\")\n",
    "    res = analyst_graph.invoke({\"table_id\": table_id, \"sub_question\": question})\n",
    "    last_message = res[\"scratchpad\"][-1]\n",
    "    print(\"DATA_ANALYST_TOOL: Run Successfully\")\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=last_message.content,\n",
    "                    tool_call_id=tool_call_id,\n",
    "                    name=\"data_analyst_tool\",\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "TOOLS = [data_analyst_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a34ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x167589650>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node = ToolNode(TOOLS)\n",
    "\n",
    "parent_graph_builder = StateGraph(ParentState)\n",
    "\n",
    "parent_graph_builder.add_node(\"reviewer_agent\", reviewer_agent)\n",
    "# parent_graph_builder.add_node(\"summariser_agent\", summariser_agent)\n",
    "parent_graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "parent_graph_builder.add_edge(START, \"reviewer_agent\")\n",
    "parent_graph_builder.add_conditional_edges(\"reviewer_agent\", tools_condition)\n",
    "# parent_graph_builder.add_conditional_edges(\"reviewer_agent\", custom_parent_tools_condition, {\"summariser_agent\": \"summariser_agent\", \"tools\": \"tools\"})\n",
    "parent_graph_builder.add_edge(\"tools\", \"reviewer_agent\")\n",
    "\n",
    "app = parent_graph_builder.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c510de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755861994.693772 1651461 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWER_AGENT: Running Hybrid Retrieval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWER_AGENT: LLM selected 3 relevant tables.\n",
      "REVIEWER_AGENT: Making tool calls...\n",
      "DATA_ANALYST_TOOL: Invoking data analyst tool...\n",
      "DATA_ANALYST_TOOL: Invoking data analyst tool...\n",
      "DATA_ANALYST_TOOL: Invoking data analyst tool...\n",
      "Running data-analyst agent...\n",
      "Running data-analyst agent...\n",
      "Running data-analyst agent...\n",
      "Executing code in python_code_executor:  Get unique values of \"Type of Land Use\" column\n",
      "Result from python_code_executor:  ['Area farmed (AAU)' 'Crops and pasture' 'Pasture' 'Hay' 'Grass silage'\n",
      " 'Total crops, fruit and horticulture' 'Beans and peas' 'Oilseed rape'\n",
      " 'Arable silage' 'Maize silage' 'Fodder rape and kale' 'Potatoes'\n",
      " 'Turnips' 'Beet' 'Vegetables for sale' 'Fruit'\n",
      " 'Nurseries, horticulture etc.' 'Other crops' 'Total cereals'\n",
      " 'Total wheat' 'Winter wheat' 'Spring wheat' 'Total oats' 'Winter oats'\n",
      " 'Spring oats' 'Total barley' 'Winter barley' 'Spring barley'\n",
      " 'Other cereals' 'Rough grazing in use']\n",
      "\n",
      "Running data-analyst agent...\n",
      "Executing code in python_code_executor:  Get unique values for Type of Crop when Statistic is Farms with Crops\n",
      "Result from python_code_executor:  ['Area farmed (AAU)' 'Commonage' 'Pasture' 'Hay' 'Grass silage'\n",
      " 'Total crops fruit and horticulture' 'Total cereals'\n",
      " 'Rough grazing in use' 'All grassland']\n",
      "\n",
      "Running data-analyst agent...\n",
      "Executing code in python_code_executor:  Get unique crop types for \"Farms with Crops\" statistic\n",
      "Result from python_code_executor:  ['Area farmed (AAU)' 'Commonage' 'Pasture' 'Hay' 'Grass silage'\n",
      " 'Total crops fruit and horticulture' 'Total cereals'\n",
      " 'Rough grazing in use' 'All grassland']\n",
      "\n",
      "Running data-analyst agent...\n",
      "Executing code in python_code_executor:  Calculate the total agricultural area in Ireland by filtering for 'Area farmed (AAU)' and 'State' and summing the 'value' column.\n",
      "Result from python_code_executor:  53543.683000000005\n",
      "\n",
      "Running data-analyst agent...\n",
      "Executing code in python_code_executor:  Calculate the total agricultural area in Ireland for 'Area farmed (AAU)' in 'Farms with Crops' category.\n",
      "Result from python_code_executor:             Statistic  Year   Region       Type of Crop     value\n",
      "0   Farms with Crops  2020  Ireland  Area farmed (AAU)  135028.0\n",
      "81  Farms with Crops  2023  Ireland  Area farmed (AAU)  129423.0\n",
      "\n",
      "Running data-analyst agent...\n",
      "DATA_ANALYST_TOOL: Run Successfully\n",
      "Executing code in python_code_executor:  Calculate the total agricultural area in Ireland by summing 'value' for 'Farms with Crops', 'Ireland' region, and 'Area farmed (AAU)' crop type.\n",
      "Result from python_code_executor:  416415.0\n",
      "\n",
      "Running data-analyst agent...\n",
      "DATA_ANALYST_TOOL: Run Successfully\n",
      "DATA_ANALYST_TOOL: Run Successfully\n"
     ]
    }
   ],
   "source": [
    "question = \"QUESTION: Give me the breakdown of renewable energy resources as a percentage share and absolute numbers in 2022 in ireland.\"\n",
    "question = \"QUESTION: How's the energy production in ireland over the years? Do a detailed comparison of renewable vs non-renewable share of energy\"\n",
    "# question = \"QUESTION: How's the wind energy production over the years?\"\n",
    "question = \"QUESTION: Did the Ukraine war have any impact on the energy production in ireland??\"\n",
    "# question = \"QUESTION: How has nuclear energy done over the years in ireland?\"\n",
    "# question = \"QUESTION: What's the impact of climate change on energy production in ireland?\"\n",
    "# question = \"QUESTION: How's the energy production in ireland over 2021-2025? Do a detailed comparison of renewable vs non-renewable share of energy\"\n",
    "question = \"QUESTION: What's the total agricultural area in Ireland?\"\n",
    "# question = \"detailed statistics on cosmetics, toileteries and related items production in prodcom data for ireland\"\n",
    "# question = \"detailed statistics on lignin based products and related items production in prodcom data for ireland\"\n",
    "# question = \"Population growth in ireland over the last 2 decades?\"\n",
    "\n",
    "\n",
    "\n",
    "res = app.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9799e3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"I've found some relevant resources. Let me do a quick analysis.\", additional_kwargs={}, response_metadata={}, id='84c6383c-2468-43f2-983c-24b48bd91e72', tool_calls=[{'name': 'data_analyst_tool', 'args': {'table_id': 'AQA06', 'question': \"QUESTION: What's the total agricultural area in Ireland?\"}, 'id': '27f78793-8abd-4549-9413-c42ae4f87bde', 'type': 'tool_call'}, {'name': 'data_analyst_tool', 'args': {'table_id': 'AVA33', 'question': \"QUESTION: What's the total agricultural area in Ireland?\"}, 'id': 'eaebbb4e-6f92-4ece-8bd8-0bd99865c35c', 'type': 'tool_call'}, {'name': 'data_analyst_tool', 'args': {'table_id': 'IFS10', 'question': \"QUESTION: What's the total agricultural area in Ireland?\"}, 'id': 'a9262b90-4bfe-4226-94ba-60472dc455f1', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='The total agricultural area in Ireland is 53543.683 hectares.', name='data_analyst_tool', id='b792218e-cdff-4a70-8200-3d5cc8fd649c', tool_call_id='27f78793-8abd-4549-9413-c42ae4f87bde'),\n",
       " ToolMessage(content='The total agricultural area in Ireland is 416,415.0.', name='data_analyst_tool', id='33565c3f-3b8b-478d-aeb0-7ee84d707822', tool_call_id='eaebbb4e-6f92-4ece-8bd8-0bd99865c35c'),\n",
       " ToolMessage(content='The total agricultural area in Ireland was 4,509,256.2 hectares in 2020 and 4,620,095.9 hectares in 2023.', name='data_analyst_tool', id='da1dec30-697e-4a62-92eb-7cfe98dab430', tool_call_id='a9262b90-4bfe-4226-94ba-60472dc455f1'),\n",
       " AIMessage(content='Based on the information available:\\n\\n*   The total agricultural area in Ireland is **53,543.683 hectares** (Source: AQA06).\\n*   Another source indicates the total agricultural area in Ireland is **416,415.0 hectares** (Source: AVA33).\\n*   Furthermore, the total agricultural area in Ireland was **4,509,256.2 hectares in 2020** and **4,620,095.9 hectares in 2023** (Source: IFS10).\\n\\nThere are discrepancies in the reported total agricultural area across different sources.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--81a3289f-5351-4e78-9182-a3de0792884d-0', usage_metadata={'input_tokens': 297, 'output_tokens': 301, 'total_tokens': 598, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 158}})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d388497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd826581",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = res[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37f09f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the information available:\\n\\n*   The total agricultural area in Ireland is **53,543.683 hectares** (Source: AQA06).\\n*   Another source indicates the total agricultural area in Ireland is **416,415.0 hectares** (Source: AVA33).\\n*   Furthermore, the total agricultural area in Ireland was **4,509,256.2 hectares in 2020** and **4,620,095.9 hectares in 2023** (Source: IFS10).\\n\\nThere are discrepancies in the reported total agricultural area across different sources.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db097d2",
   "metadata": {},
   "source": [
    "## Fixing context-isolation problem\n",
    "\n",
    "state:\n",
    "    - messages: List[str]\n",
    "    - relevant_docs: List[Dict]\n",
    "        - table_id: str\n",
    "        - context: str\n",
    "        - analysis_plan: str\n",
    "    - question: str\n",
    "    - iter: int\n",
    "         \n",
    "reviewer-agent\n",
    "    - has access to data-cso hybrid-retrieval tool - given a user prompt, it may choose to call this hybrid-retrieval tool. This tool updates the `relevant_docs` in state, and also returns a ToolMessage containing all context for all tables it retrieved\n",
    "    - it also has access to the planner tool, which is basically an agent. it takes in the `messages`, creates a low-level plan for each data-source analysis and updates the `relevant_docs` with the plan. Also it returns a ToolMessage containing the plan for all tables\n",
    "    - finally, it has access to the data-analyst subgraph as a tool. It can make multiple tool-calls to this tool. The tool node containing this subgraph will call the subgraph with the `table_id`, `question`, `analysis_plan`, and the `context`.\n",
    "\n",
    "Giving this level of autonomy may have the following effect:\n",
    "- Pros: context-isolation problem may be fixed\n",
    "- Cons: redundant recursive loops, uncertainty in making tool-calls / malformed tool-calls, hallucinations, or even premature answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bb090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
